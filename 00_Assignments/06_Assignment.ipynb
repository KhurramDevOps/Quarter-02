{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAD0+lGO+j7I8u78jopE0I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhurramDevOps/Quarter-02/blob/master/06_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploring LLM Models for Creative Video Generation and Script Analysis**"
      ],
      "metadata": {
        "id": "po5GrGaBcIyd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wnUybBFyFrHo",
        "outputId": "139d8026-e9c8-495f-8af8-d7f9eeca3edc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.10/dist-packages (2.0.7)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.8.3)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.3.25)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (2.10.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.25.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.25.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.2.3)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.15->langchain-google-genai) (9.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.68.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (0.14.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain-google-genai) (2.2.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.3.15->langchain-google-genai) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GENAI_KEY = userdata.get('GOOGLE_API_KEY_1')"
      ],
      "metadata": {
        "id": "RI-FxeaJF6dU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ],
      "metadata": {
        "id": "w_5oj3S3GLXv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "llm =  ChatGoogleGenerativeAI(\n",
        "    api_key = GENAI_KEY,\n",
        "    model = \"gemini-2.0-flash-exp\",\n",
        ")"
      ],
      "metadata": {
        "id": "FUUsPO0lGjHa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video Generation Prompt: I have used this prompt for video Generation Using VEED STUDIO\"\n",
        "\n",
        "**Prompt:**\n",
        "A fast-paced, one-minute video highlighting the journey of innovation and transformation. The video begins with a young inventor sketching ideas on a notepad under the dim glow of a desk lamp. The camera zooms into the sketches, transforming them into a real-world 3D model of a robotic arm, lifting a box in a modern, high-tech factory.\n",
        "\n",
        "The scene shifts to a montage of breakthroughs in various fields: a scientist holding a glowing test tube in a research lab, engineers assembling a clean energy plant, and a futuristic city filled with electric cars, solar panels, and green spaces. Each clip transitions smoothly, keeping the energy high.\n",
        "\n",
        "Halfway through, the focus shifts to the collaborative spirit of humanity: teams working together on tech projects, people sharing knowledge through virtual screens, and communities coming together to solve challenges like climate change and food scarcity. A quick shot of diverse individuals planting vertical gardens in an urban setting symbolizes sustainable progress.\n",
        "\n",
        "The video ends with a sweeping aerial shot of Earth from a satellite, showing green innovations and bustling cities. A simple text overlay appears: **\"Innovation powered by unity.\"**\n",
        "\n",
        "---\n",
        "\n",
        "## Style and Details:\n",
        "\n",
        "- **Resolution:** 4K Ultra HD.\n",
        "- **Lighting:** Bright, warm, and optimistic with a focus on green, natural tones.\n",
        "- **Camera Movements:** Quick cuts, dramatic zoom-ins, and smooth pans for an energetic and modern feel.\n",
        "- **Mood:** Inspiring, optimistic, and forward-looking.\n",
        "- **Duration:** 60 seconds.\n",
        "- **Sound Effects:** The hum of machines, soft background conversation, and the swoosh of futuristic tech.\n",
        "- **Music:** A hopeful, upbeat track with a gradual crescendo, leading to a powerful and uplifting finish.\n"
      ],
      "metadata": {
        "id": "Rp1YF9kHG6na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "# Upload video file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# List uploaded files\n",
        "for filename in uploaded.keys():\n",
        "    print(f'Uploaded file: {filename}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "SNsZuPU5HMS5",
        "outputId": "187b7bfb-98d9-4364-bcca-1636eb6bb866"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-19ea7180-f00f-4567-83f4-c8dd6217f63e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-19ea7180-f00f-4567-83f4-c8dd6217f63e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Innovation Unleashed_ Unity in Progress-VEED.mp4 to Innovation Unleashed_ Unity in Progress-VEED (2).mp4\n",
            "Uploaded file: Innovation Unleashed_ Unity in Progress-VEED (2).mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import Client\n",
        "client = Client(api_key=GENAI_KEY)"
      ],
      "metadata": {
        "id": "R1lhHgmgNlKA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model: str = \"gemini-2.0-flash-exp\""
      ],
      "metadata": {
        "id": "vBcthwgWWqhn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video Upload Function\n",
        "This code uploads a video file to the server and continuously checks its processing status. Once complete, it retrieves the video's URI for further use. If processing fails, an error is raised.\n"
      ],
      "metadata": {
        "id": "uqeQ8_ZFbdO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(path=\"/content/Innovation Unleashed_ Unity in Progress-VEED (1).mp4\")\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "      print('Waiting for video to be processed.')\n",
        "      time.sleep(10)\n",
        "      video_file = client.files.get(name=video_file.name or \"\")\n",
        "\n",
        "  if video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "  print(f'Video processing complete: ' + (video_file.uri or \"\"))\n",
        "\n",
        "  return video_file\n",
        "\n",
        "pottery_video = upload_video('Pottery.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4jkK1ovWtXg",
        "outputId": "3909978a-5591-4eb7-a401-89737b20f927"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Waiting for video to be processed.\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/sy0l4w8c48ir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video Caption Generator\n",
        "This function generates detailed, time-coded captions for a video using the GENAI API and a specified AI model. It takes a video file URI as input, applies a custom prompt to describe scenes with captions and spoken text, and formats the output in Markdown for easy readability and use in presentations or documentation.\n"
      ],
      "metadata": {
        "id": "0VnH62iXb_Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from IPython.display import display, Audio ,Markdown"
      ],
      "metadata": {
        "id": "eNIxXHFOXLeB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.genai.types import Part, Content\n",
        "def generate_video_captions(video):\n",
        "\n",
        "    # Predefined model and client\n",
        "    model = \"gemini-2.0-flash-exp\"  # Replace with your actual model name\n",
        "    client: Client = genai.Client(\n",
        "    api_key=GENAI_KEY,\n",
        "    )\n",
        "    prompt = \"\"\"For each scene in this video,\n",
        "                generate captions that describe the scene, along with spoken text.\n",
        "                Place each caption into an object with the timecode of the caption in the video.\n",
        "             \"\"\"\n",
        "\n",
        "    # Generate content using the API\n",
        "    response = client.models.generate_content(\n",
        "        model=model,\n",
        "        contents=[\n",
        "            Content(\n",
        "                role=\"user\",\n",
        "                parts=[\n",
        "                    Part.from_uri(\n",
        "                        file_uri=video.uri or \"\",\n",
        "                        mime_type=video.mime_type or \"\"\n",
        "                    ),\n",
        "                ]\n",
        "            ),\n",
        "            prompt,\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Extract and format the response as Markdown\n",
        "    scenes = response.text\n",
        "    return Markdown(scenes)\n"
      ],
      "metadata": {
        "id": "CeF-9HY-aYqi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_video_captions(pottery_video)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pQXqZSauaoTl",
        "outputId": "c3c3d8eb-6890-436d-cc40-adb20b839e69"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n[\n  {\n    \"timecode\": \"00:00\",\n    \"caption\": \"A hand draws a building on paper with a pencil. The words “IN A WORLD” appear on the screen along with a globe emoji.\",\n     \"spoken_text\": \"In a world\"\n  },\n    {\n    \"timecode\":\"00:01\",\n    \"caption\": \"A hand continues drawing on the paper, the words “DRIVEN BY INNOVATION” and a light bulb emoji appear.\",\n    \"spoken_text\":\"driven by innovation, \"\n  },\n {\n    \"timecode\":\"00:02\",\n    \"caption\": \"The words “IDEA BEGINS WITH A” and lightbulb emoji appear.\",\n    \"spoken_text\":\"every great idea begins with a \"\n },\n  {\n    \"timecode\":\"00:04\",\n     \"caption\": \"The words “SPARK OF CREATIVITY” appear with a picture frame emoji\",\n     \"spoken_text\":\"spark of creativity. \"\n   },\n  {\n   \"timecode\": \"00:05\",\n   \"caption\": \"The words “PICTURE A YOUNG INVENTOR” appear with an orange ball of yarn emoji.\",\n   \"spoken_text\": \"Picture a young inventor\"\n  },\n {\n    \"timecode\": \"00:07\",\n     \"caption\": \"The words “HUNCHED OVER A NOTEPAD” and an orange ball of yarn emoji appear.\",\n      \"spoken_text\":\"hunched over a notepad,\"\n },\n  {\n  \"timecode\":\"00:09\",\n  \"caption\":\"The words “DREAMS UNDER THE” and an orange ball of yarn emoji appear.\",\n  \"spoken_text\":\"sketching dreams under the soft glow of a desk lamp.\"\n },\n {\n    \"timecode\":\"00:13\",\n     \"caption\":\"A post office emoji appears with the words “THOSE SKETCHES”\",\n     \"spoken_text\":\"Those sketches\"\n  },\n{\n   \"timecode\":\"00:14\",\n   \"caption\": \"The words “DON’T JUST STAY ON PAPER” appear\",\n   \"spoken_text\":\"don't just stay on paper.\"\n  },\n   {\n   \"timecode\":\"00:15\",\n    \"caption\":\"A robotic arm in a factory is in motion, a mechanical arm emoji is shown, and “THEY LEAD” appears.\",\n    \"spoken_text\":\"They lead\"\n  },\n {\n    \"timecode\":\"00:16\",\n      \"caption\":\"The words “TO LIFE AS A ROBOTIC ARM” appear with a mechanical arm emoji.\",\n      \"spoken_text\":\"to life as a robotic arm\"\n  },\n  {\n    \"timecode\":\"00:18\",\n     \"caption\": \"The words “EFFORTLESSLY LIFTING BOXES” appear with a pair of scissors emoji.\",\n     \"spoken_text\":\"effortlessly lifting boxes\"\n  },\n  {\n    \"timecode\":\"00:20\",\n    \"caption\":\"The words “IN A CUTTING EDGE FACTORY” and light bulb emoji appear.\",\n    \"spoken_text\": \"in a cutting edge factory. Innovation doesn't stop there.\"\n  },\n{\n  \"timecode\":\"00:23\",\n  \"caption\":\"Footprint emojis appear with the words “ITS A RELENTLESS JOURNEY”.\",\n   \"spoken_text\":\"It's a relentless journey\"\n  },\n{\n    \"timecode\":\"00:25\",\n     \"caption\":\"A green test tube emoji appears with the words “THROUGH BREAKTHROUGHS”.\",\n      \"spoken_text\":\"through breakthroughs\"\n  },\n {\n  \"timecode\":\"00:26\",\n  \"caption\":\"The words “IN SCIENCE AND TECHNOLOGY” appear along with a green test tube emoji.\",\n   \"spoken_text\":\"in science and technology.\"\n  },\n {\n  \"timecode\":\"00:28\",\n   \"caption\":\"A scientist emoji holding a green test tube appears with the words “IMAGINE A”\",\n    \"spoken_text\":\"Imagine a\"\n  },\n {\n \"timecode\":\"00:29\",\n \"caption\":\"The words “SCIENTIST IN A LAB” appear with a scientist emoji holding a green test tube\",\n \"spoken_text\":\"scientist in a lab\"\n  },\n{\n   \"timecode\":\"00:30\",\n   \"caption\":\"The words “HOLDING A GLOWING TEST TUBE” appear with a yellow moon emoji.\",\n    \"spoken_text\":\"holding a glowing test tube\"\n  },\n{\n   \"timecode\":\"00:33\",\n   \"caption\": \"A yellow moon emoji appears with the words “A SYMBOL OF DISCOVERY”\",\n   \"spoken_text\":\"a symbol of discovery.\"\n   },\n{\n  \"timecode\":\"00:34\",\n \"caption\": \"A safety vest emoji appears with the words “ENGINEERS”\",\n \"spoken_text\":\"Engineers\"\n },\n{\n  \"timecode\":\"00:36\",\n  \"caption\":\"A safety vest emoji appears with the words “ARE HARD AT WORK”\",\n  \"spoken_text\":\"are hard at work\"\n },\n{\n   \"timecode\":\"00:37\",\n \"caption\":\"The words “ASSEMBLING CLEAN ENERGY PLANTS” appear with a lightning bolt emoji.\",\n  \"spoken_text\":\"assembling clean energy plants\"\n },\n{\n   \"timecode\":\"00:38\",\n \"caption\": \"The words “THAT PROMISE A SUSTAINABLE FUTURE” and lightning bolt emoji appear.\",\n \"spoken_text\":\"that promise a sustainable future.\"\n  },\n{\n  \"timecode\":\"00:41\",\n  \"caption\":\"Sunglasses emoji appear with the words “AND THEN THERES” \",\n  \"spoken_text\":\"And then there's\"\n  },\n{\n  \"timecode\":\"00:42\",\n \"caption\":\"Sunglasses appear with the words “THE VISION OF A FUTURISTIC CITY”\",\n \"spoken_text\":\"the vision of a futuristic city\"\n },\n{\n   \"timecode\":\"00:45\",\n \"caption\":\"The words “ALIVE WITH ELECTRIC CARS” and a lightning bolt emoji appear.\",\n \"spoken_text\":\"alive with electric cars,\"\n  },\n {\n  \"timecode\":\"00:46\",\n  \"caption\":\"The words “SOLAR PANELS AND LUSH GREEN SPACES” appear.\",\n  \"spoken_text\":\"solar panels and lush green spaces.\"\n   },\n{\n  \"timecode\":\"00:49\",\n  \"caption\":\"A heart emoji appears with the words “BUT THE HEART OF INNOVATION LIES”\",\n  \"spoken_text\":\"But the heart of innovation lies\"\n },\n{\n    \"timecode\":\"00:50\",\n \"caption\":\"The words “IN COLLABORATION” appear.\",\n \"spoken_text\":\"in collaboration.\"\n  },\n{\n    \"timecode\":\"00:52\",\n    \"caption\":\"The words “TEAMS UNITE, SHARING” appear with a stack of books emoji\",\n     \"spoken_text\":\"Teams unite, sharing\"\n   },\n {\n   \"timecode\":\"00:53\",\n   \"caption\":\"The words “KNOWLEDGE ACROSS VIRTUAL SCREENS” appear with a stack of books emoji.\",\n   \"spoken_text\":\"knowledge across virtual screens.\"\n   },\n{\n   \"timecode\":\"00:56\",\n   \"caption\": \"The words “TEAM TACKLING THE WORLD’S TOUGHEST CHALLENGES” and a person with person emoji appear.\",\n     \"spoken_text\":\"team tackling the world's toughest challenges.\"\n   },\n {\n    \"timecode\":\"00:57\",\n  \"caption\": \"A back and forth arrow emoji appears with the words “CLIMATE”\",\n   \"spoken_text\":\"climate\"\n },\n {\n  \"timecode\":\"00:58\",\n \"caption\":\"A back and forth arrow emoji appears with the words “CHANGE, FOOD”\",\n  \"spoken_text\":\"change, food\"\n },\n {\n   \"timecode\":\"01:00\",\n  \"caption\":\"The words “SCARCITY AND” appear with a back and forth arrow emoji.\",\n   \"spoken_text\":\"and\"\n },\n {\n  \"timecode\":\"01:01\",\n  \"caption\":\"The words “DIVERSE INDIVIDUALS” and a person with person emoji appear.\",\n    \"spoken_text\":\"Diverse individuals\"\n },\n{\n  \"timecode\":\"01:03\",\n \"caption\":\"The words “COME TOGETHER PLANTING” appear with a person with person emoji\",\n \"spoken_text\":\"come together, planting\"\n  },\n {\n  \"timecode\":\"01:04\",\n  \"caption\":\"The words “VERTICAL GARDENS IN URBAN LANDSCAPES” appear with an up and down arrow emoji.\",\n \"spoken_text\":\"vertical gardens in urban landscapes,\"\n  },\n{\n  \"timecode\":\"01:05\",\n  \"caption\":\"A pregnant person emoji appears with the words “NURTURING SUSTAINABLE”\",\n   \"spoken_text\":\"nurturing sustainable\"\n  },\n{\n    \"timecode\":\"01:07\",\n   \"caption\":\"The words “PROGRESS WHERE ITS NEEDED MOST” appear.\",\n    \"spoken_text\":\"progress right where it's needed most.\"\n  },\n{\n    \"timecode\":\"01:09\",\n  \"caption\":\"A magnifying glass emoji appears with the words “AS WE ZOOM OUT”\",\n  \"spoken_text\":\"As we zoom out,\"\n   },\n{\n  \"timecode\":\"01:11\",\n  \"caption\":\"The words “WE SEE EARTH FROM ABOVE” and magnifying glass emoji appear.\",\n   \"spoken_text\":\"we see Earth from above,\"\n   },\n{\n  \"timecode\":\"01:12\",\n  \"caption\":\"A rainbow emoji appears with the words “A VIBRANT”\",\n   \"spoken_text\":\"a vibrant\"\n   },\n{\n    \"timecode\":\"01:13\",\n   \"caption\":\"A rainbow emoji appears with the words “TAPESTRY OF GREEN INNOVATIONS”\",\n   \"spoken_text\":\"tapestry of green innovations\"\n   },\n{\n    \"timecode\":\"01:15\",\n \"caption\":\"The words “AND BUSTLING CITIES” appear with a rainbow emoji\",\n  \"spoken_text\":\"and bustling cities.\"\n   },\n{\n    \"timecode\":\"01:16\",\n  \"caption\":\"A flexed biceps emoji appears with the words “THIS”\",\n    \"spoken_text\":\"This\"\n },\n{\n  \"timecode\":\"01:17\",\n  \"caption\":\"The words “IS THE POWER OF UNITY” appear with a flexed bicep emoji.\",\n    \"spoken_text\":\"is the power of unity\"\n  },\n{\n   \"timecode\":\"01:18\",\n  \"caption\":\"The words “IN INNOVATION” appear.\",\n  \"spoken_text\":\"in innovation.\"\n   },\n{\n   \"timecode\":\"01:19\",\n    \"caption\":\"A person with person emoji appears with the words “TOGETHER”\",\n    \"spoken_text\":\"Together,\"\n  },\n {\n \"timecode\":\"01:20\",\n  \"caption\":\"A person with person emoji appears with the words “WE'RE NOT JUST”\",\n   \"spoken_text\":\"we're not just\"\n  },\n {\n   \"timecode\":\"01:21\",\n  \"caption\": \"A house emoji appears with the words “IMAGINING THE FUTURE”\",\n   \"spoken_text\":\"imagining the future,\"\n },\n  {\n  \"timecode\":\"01:23\",\n  \"caption\":\"The words “WE’RE BUILDING IT” appear.\",\n   \"spoken_text\":\"we're building it.\"\n }\n]\n```"
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reflection on the Experience**\n",
        "\n",
        "####Throughout this assignment, I encountered significant challenges in finding a suitable text-to-video model that could be used for free in Google Colab. I explored several options, including platforms like Runway, Pictory, Pixel AI, and Synthesia, but most of them either required paid plans or did not offer the flexibility I needed. Despite attempting to integrate over 10 to 15 different models, I couldn't find a workable solution within the constraints of free access.\n",
        "\n",
        "####Given these limitations, I decided to take an alternative approach by utilizing the Gemini LLM with LangChain for video analysis. This allowed me to focus on generating a detailed script and timeline from the video, which still fulfilled the assignment's objectives. While it wasn't the original text-to-video generation I envisioned, it provided valuable insights into the power of LLMs in content creation and analysis.\n",
        "\n",
        "####Overall, this experience taught me the importance of flexibility and creative problem-solving when facing technical constraints. It also highlighted the need to adapt to available resources and find innovative ways to achieve the desired outcomes.\n"
      ],
      "metadata": {
        "id": "65d6j_2oJiTa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1hNYIZEyJt45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}