{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVl8dmLRtVdUrxVbWQkLE+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhurramDevOps/Quarter-02/blob/master/Rag_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain-pinecone langchain-google-genai"
      ],
      "metadata": {
        "id": "4anGvSmstwJc"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install google-auth google-auth-oauthlib google-auth-httplib2\n",
        "# !pip install langchain"
      ],
      "metadata": {
        "collapsed": true,
        "id": "v4Z9RtFC3ikC"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/my-gemini-api-444713-262839e78ed5.json\""
      ],
      "metadata": {
        "id": "v_7Bevsc3hrT"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "from google.colab import userdata\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "pinecone_api_key = userdata.get('pinecone_api')\n",
        "pc = Pinecone(api_key=pinecone_api_key)"
      ],
      "metadata": {
        "id": "6WIBLSanuE0m"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_name = \"practise-rag-project\"\n",
        "\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=768,\n",
        "    metric='cosine',\n",
        "    spec  = ServerlessSpec(cloud=\"aws\",region=\"us-east-1\"),\n",
        ")\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "46Ggs_N1u4wo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import os\n",
        "\n",
        "GEMINI_KEY = userdata.get(\"GOOGLE_API_KEY_1\")\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")"
      ],
      "metadata": {
        "id": "3CyHNRdtwqTG"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = embeddings.embed_query(\"Building a Rag project! \")\n",
        "\n"
      ],
      "metadata": {
        "id": "hlltV7HQxP2S"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBlcW09p39TY",
        "outputId": "a7305abf-5dc2-4187-ea3b-1d6b9f85457d"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.005886509083211422,\n",
              " -0.01920737698674202,\n",
              " -0.01310189813375473,\n",
              " -0.03790365159511566,\n",
              " -0.003551947884261608]"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
      ],
      "metadata": {
        "id": "_9sdtw5C4MgY"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I have chocolate chip pancake and scrambled eggs for breakfast\",\n",
        "    metadata={\"source\": \"personal\", \"meal\": \"breakfast\"}\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"LangChain is a framework for building applications with LLMs (Large Language Models), such as GPT. It provides tools to manage chains, agents, and memory for building more advanced AI applications.\",\n",
        "    metadata={\"topic\": \"LangChain\", \"category\": \"AI Framework\"}\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Agentic AI refers to autonomous AI systems that are capable of decision-making, learning, and adaptation in real-world environments without needing constant human intervention.\",\n",
        "    metadata={\"topic\": \"Agentic AI\", \"category\": \"Artificial Intelligence\", \"importance\": \"High\"}\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"In the latest world news, a new tech company has developed an innovative AI that is able to solve real-world problems faster than previous models, pushing the boundaries of automation and efficiency.\",\n",
        "    metadata={\"topic\": \"Tech News\", \"date\": \"2025-01-02\", \"company\": \"Innovative AI Company\"}\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"The use of AI in healthcare is growing rapidly. Recent advancements in diagnostic AI tools are helping doctors identify diseases more accurately and faster, significantly improving patient outcomes.\",\n",
        "    metadata={\"topic\": \"Healthcare AI\", \"category\": \"Medical Technology\", \"impact\": \"Positive\"}\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"LangChain offers a wide range of tools to work with LLMs. This includes support for document search, question-answering systems, and memory management to make intelligent agents more effective in real-world tasks.\",\n",
        "    metadata={\"topic\": \"LangChain\", \"category\": \"AI Tools\", \"use_case\": \"Advanced workflows\"}\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"Agentic AI is becoming increasingly important in industries like autonomous vehicles, robotics, and smart cities, where real-time decision-making and adaptability are crucial for success.\",\n",
        "    metadata={\"topic\": \"Agentic AI\", \"category\": \"Industry Applications\", \"industries\": [\"Autonomous Vehicles\", \"Robotics\", \"Smart Cities\"]}\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"A new world record has been set for the fastest internet speed, with researchers breaking through previous limitations using advanced fiber-optic technology, promising faster and more efficient global communication.\",\n",
        "    metadata={\"topic\": \"Tech News\", \"category\": \"Innovation\", \"record\": \"Fastest Internet Speed\", \"date\": \"2025-01-02\"}\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"In a recent study, AI-powered chatbots have been shown to outperform human customer service agents in resolving technical issues, reducing wait times and improving customer satisfaction.\",\n",
        "    metadata={\"topic\": \"AI in Customer Service\", \"category\": \"Business Technology\", \"impact\": \"High\"}\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"LangChain continues to evolve with new integrations, including support for databases, APIs, and external data sources, enabling more complex and efficient workflows for AI applications.\",\n",
        "    metadata={\"topic\": \"LangChain\", \"category\": \"Development\", \"features\": [\"Database Integration\", \"API Support\", \"External Data Sources\"]}\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1, document_2, document_3, document_4, document_5,\n",
        "    document_6, document_7, document_8, document_9, document_10\n",
        "]\n"
      ],
      "metadata": {
        "id": "sLrXsh6i-XQe"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(  documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMecEO6DEyFH",
        "outputId": "9fc433c4-3035-46bb-fc86-0fad2576e18c"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "uuid4()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1NDT1oiEoko",
        "outputId": "bc4a5b9b-c1a4-4728-ee7e-a2949d8441cc"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UUID('313c8987-e230-4088-8530-7e71b0740cb8')"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uuids = [str(uuid4()) for i in range (len(documents))]\n",
        "vector_store.add_documents(documents=documents, ids=uuids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RquzIMr0E1sN",
        "outputId": "d6dbb66c-8fdb-4d03-ef9c-550a6ba349a6"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['c1c41343-a04a-4ef0-b206-62d1eb4d6a9a',\n",
              " '091fc645-3744-4ee8-99bb-967cb6802791',\n",
              " '487fbb31-94d9-4243-a882-99596a014a83',\n",
              " '97354cc2-00ed-4f5c-b8d4-147f19eee87d',\n",
              " '64e758fb-6da8-43f3-897c-ef319e6b08bf',\n",
              " '3ed98dca-6d78-498b-be7c-4cdeca7c0f30',\n",
              " '6ab198bd-91ae-4671-8536-a85136f7e602',\n",
              " '91dc49e9-fb06-45f7-8473-a5f93dee31b8',\n",
              " '0dda22cc-2730-461d-a98a-2b9d6b27ae6e',\n",
              " 'eed046ec-76a3-4843-96b8-c10ab4098e71']"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_result = vector_store.similarity_search(\n",
        "    \"Who won 2024 FIFA World Cup?\", k=7\n",
        ")\n",
        "print(vector_result[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hh2hyKCFcl6",
        "outputId": "bd346db2-41d2-4c10-820e-67c478f8f144"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a recent study, AI-powered chatbots have been shown to outperform human customer service agents in resolving technical issues, reducing wait times and improving customer satisfaction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "VCi4vqUS5eaf"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_answer(question):\n",
        "\n",
        "  vector_result = vector_store.similarity_search(question, k=5)\n",
        "\n",
        "  llm = ChatGoogleGenerativeAI(\n",
        "      api_key=GEMINI_KEY,\n",
        "      model = \"gemini-2.0-flash-exp\",\n",
        "      max_tokens= 100,\n",
        "      temperature=0.7\n",
        "  )\n",
        "\n",
        "  prompt1= PromptTemplate(\n",
        "      input_variables=[\"question\"],\n",
        "      template = \"Using this data {vector_result} . Answer the following question: \\n\\n{question}\"\n",
        "  )\n",
        "  chain1= prompt1 | llm\n",
        "\n",
        "  final_answer = chain1.invoke({\"vector_result\": vector_result, \"question\": question})\n",
        "\n",
        "  return final_answer"
      ],
      "metadata": {
        "id": "h6AKlz2P59yM"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = user_answer(\"What's the latest news?\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ROL8pmS27d12"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "z09QFgku7imb",
        "outputId": "dbd31b92-88f6-4d14-e413-364a525801c5"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the provided data, here's the latest news:\n\n*   **A new tech company (Innovative AI Company) has developed an innovative AI that can solve real-world problems faster than previous models.** This is highlighted in multiple documents with the same content and metadata.\n*   **LangChain is evolving with new integrations, including support for databases, APIs, and external data sources.** This allows for more complex and efficient workflows for AI applications.\n\nIt's worth noting that the"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_1 = user_answer(\"What is Langchain and where it is used ?\")\n"
      ],
      "metadata": {
        "id": "CTK0435lMLvC"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response_1.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "0-3RXtyRMfD9",
        "outputId": "13867786-08ce-4ea5-e1c5-3a66953a0782"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "LangChain is a framework for building applications with Large Language Models (LLMs), such as GPT. It provides tools to manage chains, agents, and memory for building more advanced AI applications. LangChain also supports integrations with databases, APIs, and external data sources, enabling more complex and efficient workflows for AI applications.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_2 = user_answer(\"What i like in breakfast , Tell me in Key points\")"
      ],
      "metadata": {
        "id": "v8Yuo6iZM-wQ"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response_2.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "KTm7YsKJNF6f",
        "outputId": "d45471e2-114f-44b1-ae0a-fa863150602b"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, based on the provided data, here are the key points about what you like for breakfast:\n\n*   **Chocolate chip pancakes:** You enjoy having chocolate chip pancakes.\n*   **Scrambled eggs:** You also like to have scrambled eggs.\n\nIt appears you consistently have these two items for breakfast according to the provided documents.\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}